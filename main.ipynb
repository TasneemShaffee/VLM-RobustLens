{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f13540",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "repo_path = \"/content/drive/MyDrive/VLM-RobustLens\"\n",
    "\n",
    "# TODO: Change this to use your personal access token (follow the instructions here: https://github.com/settings/tokens)\n",
    "# This isn't secure, but the repository is private anyway. \n",
    "token = \"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\"\n",
    "\n",
    "if os.path.exists(repo_path):\n",
    "  shutil.rmtree(repo_path)\n",
    "  print(\"Removed old repo.\")\n",
    "\n",
    "# TODO: change this to your branch\n",
    "branch = \"mjy\"\n",
    "\n",
    "url = f\"https://{token}@github.com/TasneemShaffee/VLM-RobustLens.git\"\n",
    "\n",
    "!git clone -b $branch --single-branch $url $repo_path\n",
    "\n",
    "# Create the directory for saving vlms if it doesn't already exist\n",
    "vlms_path = \"/content/drive/MyDrive/vlms\"\n",
    "if not os.path.exists(vlms_path):\n",
    "  os.makedirs(vlms_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe41f528",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Note: this will take a LONG time. If this is the first time you're running this cell, \n",
    "# don't run it on a GPU runtime.\n",
    "\n",
    "%%bash\n",
    "mkdir -p /content/drive/MyDrive/Datasets\n",
    "cd /content/drive/MyDrive/Datasets\n",
    "\n",
    "# Download COCO dataset\n",
    "if [ ! -d \"val2014\" ]; then\n",
    "  echo \"Downloading COCO dataset...\"\n",
    "  wget http://images.cocodataset.org/zips/val2014.zip\n",
    "  unzip -n val2014.zip\n",
    "  rm val2014.zip\n",
    "else\n",
    "  echo \"COCO dataset already exists.\"\n",
    "fi\n",
    "\n",
    "# Download the VQA-rephrasings dataset\n",
    "if [ ! -d \"vqa_rephrasings\" ]; then\n",
    "  echo \"Downloading VQA-Rephrasings...\"\n",
    "  wget https://facebookresearch.github.io/VQA-Rephrasings/assets/data/vqa_rephrasings.tar.gz\n",
    "  mkdir vqa_rephrasings\n",
    "  tar -xzf vqa_rephrasings.tar.gz -C vqa_rephrasings\n",
    "  rm vqa_rephrasings.tar.gz\n",
    "else\n",
    "  echo \"VQA-Rephrasings dataset already exists...\"\n",
    "fi\n",
    "\n",
    "# Download the Visual Genome dataset\n",
    "if [ ! -f \"/content/drive/MyDrive/Datasets/question_answers.json\" ]; then\n",
    "  echo \"Downloading Visual Genome QA dataset...\"\n",
    "  wget https://homes.cs.washington.edu/~ranjay/visualgenome/data/dataset/question_answers.json.zip\n",
    "  unzip -n question_answers.json.zip\n",
    "  rm question_answers.json.zip\n",
    "\n",
    "  echo \"Downloading Visual Genome images dataset part 1...\"\n",
    "  wget https://cs.stanford.edu/people/rak248/VG_100K_2/images.zip\n",
    "  unzip -n images.zip\n",
    "  rm images.zip\n",
    "\n",
    "  echo \"Downloading Visual Genome images dataset part 2...\"\n",
    "  wget https://cs.stanford.edu/people/rak248/VG_100K_2/images2.zip\n",
    "  unzip -n images2.zip -d VG_100K\n",
    "  rm images2.zip\n",
    "else\n",
    "    echo \"Visual Genome datasets already exist.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46ed2f7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Note: this will take some time. Collab will ask you to restart your session, which you should do.\n",
    "# After restarting, rerun all of the previous cells (including this one).\n",
    "\n",
    "reqs_path = f\"{repo_path}/requirements.txt\"\n",
    "!pip install -r $reqs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c47807",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# # Uncomment to run the cyclic consistency dataset on Qwen3VL\n",
    "# json_path = \"../Datasets/vqa_rephrasings/compressed/v2_OpenEnded_mscoco_valrep2014_humans_og_questions.json\"\n",
    "# image_path = \"../Datasets/val2014\"\n",
    "\n",
    "# %cd /content/drive/MyDrive/VLM-RobustLens\n",
    "# !python main.py \\\n",
    "#     --cache_dir /content/drive/MyDrive/vlms \\\n",
    "#     --model_name \"qwen3vl\" \\\n",
    "#     --save_frequency 5 \\\n",
    "#     --max_images 600 \\\n",
    "#     --dataset \"cyc\" \\\n",
    "#     --json_path \"{json_path}\" \\\n",
    "#     --image_path \"{image_path}\" \\\n",
    "#     --attn_mode \"full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd0666c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment to run the Visual Genome dataset on Qwen3VL\n",
    "json_path = \"../Datasets/grammatical_question_answers.json\"\n",
    "image_path = \"../Datasets/VG_100K\"\n",
    "\n",
    "%cd /content/drive/MyDrive/VLM-RobustLens\n",
    "!python main.py \\\n",
    "    --cache_dir /content/drive/MyDrive/vlms \\\n",
    "    --model_name \"qwen3vl\" \\\n",
    "    --save_frequency 5 \\\n",
    "    --max_images 600 \\\n",
    "    --dataset \"vg\" \\\n",
    "    --json_path \"{json_path}\" \\\n",
    "    --image_path \"{image_path}\" \\\n",
    "    --attn_mode \"full\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
